pruning:
  sparsity_function: "PolynomialDecay"
  init_sparsity: 0.05  # 降低初始稀疏度以保持模型稳定性
  final_sparsity: 0.5   # 降低最终稀疏度以平衡压缩率和精度
  start_step: 5000
  end_step: 15000
  update_frequency: 200

quantization:
  bits: 8
  quantization_type: "INT8"  # 使用更标准的INT8量化
  compute_type_nvidia: "float16"  # 统一使用float16
  compute_type_universal: "float16"
  double_quantization: true
  group_size: 64      # 降低group_size以适应更多设备
  fallback_group_sizes: [32, 16, 8]  # 增加更多fallback选项

lora:
  rank: [16, 32]
  alpha: 32
  learning_rate: 1e-5
  batch_size: 2  # 减少批大小以适应GPU内存限制
  epochs: 3      # 减少训练轮次以节省时间
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]

dataset:
  zh_wiki_path: "C:/Users/73524/Documents/zhwiki-20250320-pages-articles-multistream.xml"
